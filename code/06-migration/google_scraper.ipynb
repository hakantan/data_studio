{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import NoSuchElementException    \n",
    "from datetime import date, timedelta\n",
    "import time\n",
    "import re\n",
    "from user_agent import generate_user_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': generate_user_agent(device_type=\"desktop\", os=('mac', 'linux'))}\n",
    "opts = webdriver.ChromeOptions()\n",
    "opts.add_argument({'User-Agent': generate_user_agent(device_type=\"desktop\", os=('mac', 'linux'))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.google.com')\n",
    "\n",
    "# Find search box, search for term\n",
    "search_box = driver.find_element_by_name('q')\n",
    "search_box.send_keys('Fl√ºchtlinge\\n')\n",
    "\n",
    "\n",
    "tools = driver.find_element_by_xpath('//*[@id=\"hdtb-tls\"]')\n",
    "tools.click()\n",
    "time.sleep(4)\n",
    "\n",
    "# setting up the timeframe I want my results to be in\n",
    "# starts january 1st, 2014, takes one week, \n",
    "# scrapes all sites, all results, grabs the links\n",
    "# once there is no 'next'-page to click on\n",
    "# clears the dates, and moves on to the next week\n",
    "\n",
    "start = date(2014, 1, 1)\n",
    "week = timedelta(days=7)\n",
    "next_day = timedelta(days=1)\n",
    "end = date(2014, 12, 31)\n",
    "scrape_start_date = start\n",
    "ending = scrape_start_date+week\n",
    "\n",
    "# Empty list to store the links in. \n",
    "links = []\n",
    "\n",
    "# This while loop tells Selenium to scrape until the end of the year 2014\n",
    "# on a week-by-week basis. \n",
    "\n",
    "while scrape_start_date < end:\n",
    "    print('---new week ---')\n",
    "    start_time = str(scrape_start_date.strftime('%m/%d/%Y'))\n",
    "    end_time = str(ending.strftime('%m/%d/%Y'))\n",
    "    print(start_time)\n",
    "    print(end_time)\n",
    "    \n",
    "    find_time = driver.find_elements_by_css_selector('div.mn-hd-txt')\n",
    "    for find in find_time:\n",
    "        if \"Zeit\" in find.text:\n",
    "            find.click()\n",
    "        elif \"2014\" in find.text:\n",
    "            find.click()\n",
    "            \n",
    "    time.sleep(1)\n",
    "    set_time = driver.find_element_by_css_selector('span#cdrlnk')\n",
    "    set_time.click()\n",
    "    time_begin = driver.find_element_by_css_selector('input#cdr_min')\n",
    "    time_end = driver.find_element_by_css_selector('input#cdr_max')\n",
    "\n",
    "    time_begin.clear()\n",
    "    time_end.clear()\n",
    "    time.sleep(0.5)\n",
    "    time_begin.send_keys(start_time)\n",
    "\n",
    "    time_end.send_keys(end_time)\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Selenium now knows what week I'm looking for. \n",
    "    # Time to click the button, start the search.\n",
    "\n",
    "    begin_search = driver.find_elements_by_class_name(\"cdr_go\")[1]\n",
    "    begin_search.click()\n",
    "\n",
    "#    urls = driver.find_elements_by_css_selector('h3.r a')\n",
    "#    for url in urls:\n",
    "#        links.append(url.get_attribute('href'))\n",
    "    next_page = driver.find_element_by_css_selector('#pnnext')\n",
    "\n",
    "    # while in the second while loop, I want the results to be in a list\n",
    "    # this gives me the chance to later look at specific weeks, if I want to.\n",
    "    # after one week is over, and new dates are set, list gets emptied.\n",
    "    \n",
    "    week_link = []\n",
    "    while next_page != None:\n",
    "        try:\n",
    "            next_page = driver.find_element_by_css_selector('#pnnext')\n",
    "            next_page.click()\n",
    "            time.sleep(5)\n",
    "            urls = driver.find_elements_by_css_selector('h3.r a')\n",
    "            for url in urls:\n",
    "                week_link.append(url.get_attribute('href'))\n",
    "\n",
    "        # if there is no \"next\"-page, the code breaks, and continues \n",
    "        # to run the original while loop it is nested in\n",
    "        \n",
    "        except NoSuchElementException:\n",
    "            print('Done with this. Date is', end_time)\n",
    "            break\n",
    "    \n",
    "    scrape_start_date = ending + next_day\n",
    "    ending = scrape_start_date + week\n",
    "    links.append(week_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.op-online.de/region/neu-isenburg/f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               links\n",
       "0  https://www.zeit.de/gesellschaft/zeitgeschehen...\n",
       "1  https://www.op-online.de/region/neu-isenburg/f..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={0: \"links\"}, inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
